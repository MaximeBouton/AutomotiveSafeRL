{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection with a crosswalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/LocalApproximationValueIteration/Dvh7I.ji for LocalApproximationValueIteration [a40420fb-f401-52da-a663-f502e5b95060]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package LocalApproximationValueIteration does not have Random in its dependencies:\n",
      "│ - If you have LocalApproximationValueIteration checked out for development and have\n",
      "│   added Random as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with LocalApproximationValueIteration\n",
      "└ Loading Random into LocalApproximationValueIteration from project dependency, future warnings for LocalApproximationValueIteration are suppressed.\n",
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/PedCar/NmDDZ.ji for PedCar [90cf7f26-d5c7-593d-a0e1-4a8367407571]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package PedCar does not have AutomotivePOMDPs in its dependencies:\n",
      "│ - If you have PedCar checked out for development and have\n",
      "│   added AutomotivePOMDPs as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with PedCar\n",
      "└ Loading AutomotivePOMDPs into PedCar from project dependency, future warnings for PedCar are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Random\n",
    "using Printf\n",
    "using Flux\n",
    "using POMDPs\n",
    "using POMDPModelTools\n",
    "using POMDPSimulators\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using DiscreteValueIteration\n",
    "using MDPModelChecking\n",
    "using StaticArrays\n",
    "using RLInterface\n",
    "using DeepQLearning\n",
    "using AutomotiveDrivingModels\n",
    "using AutomotivePOMDPs\n",
    "using AutomotiveSensors\n",
    "using LocalApproximationValueIteration\n",
    "using Reel\n",
    "using AutoViz\n",
    "using ProgressMeter\n",
    "using JLD2\n",
    "using FileIO\n",
    "using BSON\n",
    "using PedCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "includet(\"../src/masking.jl\")\n",
    "includet(\"../src/util.jl\")\n",
    "includet(\"../src/masked_dqn.jl\")\n",
    "includet(\"../src/qmdp_approximation.jl\")\n",
    "includet(\"../src/render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1);\n",
    "cam = FitToContentCamera(0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = UrbanParams(nlanes_main=1,\n",
    "                     crosswalk_pos =[VecSE2(6, 0., pi/2), VecSE2(-6, 0., pi/2), VecSE2(0., -5., 0.)],\n",
    "                     crosswalk_length =  [14.0, 14., 14.0],\n",
    "                     crosswalk_width = [4.0, 4.0, 3.1],\n",
    "                     stop_line = 22.0)\n",
    "env = UrbanEnv(params=params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Discrete states MDP **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = PedCarMDP(env=env, pos_res=2.0, vel_res=2., ped_birth=0.7, car_birth=0.7);\n",
    "init_transition!(mdp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial resolution 2.0 m \n",
      "pedestrian velocity resolution 1.0 m/s \n",
      "car velocity resolution 2.0 m/s \n",
      "number of states 23456940 \n",
      "number of actions 4 \n"
     ]
    }
   ],
   "source": [
    "@printf(\"spatial resolution %2.1f m \\n\", mdp.pos_res)\n",
    "@printf(\"pedestrian velocity resolution %2.1f m/s \\n\", mdp.vel_ped_res)\n",
    "@printf(\"car velocity resolution %2.1f m/s \\n\", mdp.vel_res)\n",
    "@printf(\"number of states %d \\n\", n_states(mdp))\n",
    "@printf(\"number of actions %d \\n\", n_actions(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous states MDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = UrbanPOMDP(env=env,\n",
    "                   sensor = PerfectSensor(),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                   max_cars=1, \n",
    "                   max_peds=1, \n",
    "                   car_birth=0.7, \n",
    "                   ped_birth=0.7, \n",
    "                   max_obstacles=0., # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"../pc_util_processed.jld2\" qmat util pol\n",
    "safe_policy = ValueIterationPolicy(mdp, qmat, util, pol);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "mask = SafetyMask(mdp, safe_policy, threshold);\n",
    "continuous_safe_policy = SafePOMDPPolicy(mask, pomdp)\n",
    "discrete_safe_random = MaskedEpsGreedyPolicy(mdp, 1.0, mask, rng)\n",
    "continuous_safe_random = RandomMaskedPOMDPPolicy(mask, pomdp, rng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnetwork = BSON.load(\"../training_scripts/drqn-log/log13/model.bson\")[:qnetwork]\n",
    "dqn_policy = NNPolicy(pomdp, qnetwork, actions(pomdp), 1)\n",
    "masked_policy = MaskedNNPolicy(pomdp, dqn_policy, mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32.214079 seconds (76.17 M allocations: 12.299 GiB, 5.74% gc time)\n",
      "Summary for 10000 episodes: \n",
      "Average reward: 0.167 \n",
      "Average # of steps: 51.077 \n",
      "Average # of violations: 0.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:31\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, safe_policy, n_ep=10000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53.469413 seconds (219.37 M allocations: 26.353 GiB, 7.81% gc time)\n",
      "Summary for 10000 episodes: \n",
      "Average reward: 0.047 \n",
      "Average # of steps: 89.573 \n",
      "Average # of violations: 1.550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:53\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, discrete_safe_random, n_ep=10000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76.335680 seconds (554.82 M allocations: 40.384 GiB, 14.30% gc time)\n",
      "Summary for 1000 episodes: \n",
      "Average reward: 0.176 \n",
      "Average # of steps: 43.842 \n",
      "Average # of violations: 2.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:13\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_policy, n_ep=1000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.912827 seconds (1.03 G allocations: 74.830 GiB, 15.27% gc time)\n",
      "Summary for 1000 episodes: \n",
      "Average reward: 0.051 \n",
      "Average # of steps: 78.408 \n",
      "Average # of violations: 3.600 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:13\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_random, n_ep=1000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Continuous Environment: Safe RL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93.323057 seconds (422.53 M allocations: 30.931 GiB, 12.89% gc time)\n",
      "Summary for 1000 episodes: \n",
      "Average reward: 0.175 \n",
      "Average # of steps: 45.101 \n",
      "Average # of violations: 3.900 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:33\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, masked_policy, n_ep=1000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation ... Avg Reward 0.93 | Violations (%) 3.50 | Avg Steps 42.72"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.929"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_policy = masked_evaluation(mask)\n",
    "scores_eval = DeepQLearning.evaluation(evaluation_policy, dqn_policy, POMDPEnvironment(pomdp),                                  \n",
    "                         1000,\n",
    "                         400,\n",
    "                         true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collisions analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.103746 seconds (566.19 k allocations: 42.512 MiB, 20.05% gc time)\n"
     ]
    }
   ],
   "source": [
    "hr = HistoryRecorder(rng=rng, max_steps=400)\n",
    "s0 = initialstate(pomdp, rng)\n",
    "up = PreviousObservationUpdater()\n",
    "o0 = generate_o(pomdp, s0, UrbanAction(0.), s0, rng)\n",
    "b0 = initialize_belief(up, o0)\n",
    "@time hist2 = simulate(hr, pomdp, masked_policy, up, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:12:49\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:12:28\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "up = PreviousObservationUpdater()\n",
    "@showprogress for ep=1:10000\n",
    "    global hist2\n",
    "    hr = HistoryRecorder(rng=rng, max_steps=100)\n",
    "    s0 = initialstate(pomdp, rng)\n",
    "    o0 = generate_o(pomdp, s0, UrbanAction(0.), s0, rng)\n",
    "    b0 = initialize_belief(up, o0)\n",
    "    hist2 = simulate(hr, pomdp, masked_policy, up, b0, s0)\n",
    "    if sum(hist2.reward_hist .< 0.) != 0.\n",
    "        println(\"Crash\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-18116190589946932949.webm?17633051715714449191\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpSjq0u0\", 0x000000000000003e, 2.0, nothing)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = hist2\n",
    "state_hist = h.state_hist\n",
    "action_hist = h.action_hist\n",
    "belief_hist = h.belief_hist\n",
    "safe_acts = [i[1] for i in h.ainfo_hist]\n",
    "probas = [i[2] for i in h.ainfo_hist]\n",
    "routes = [i[3] for i in h.ainfo_hist]\n",
    "\n",
    "push!(safe_acts, [UrbanAction(NaN)])\n",
    "push!(probas, [NaN])\n",
    "push!(routes, PedCar.OFF_ROUTE)\n",
    "push!(action_hist, UrbanAction(NaN))\n",
    "duration, fps, render_hist = animate_states(pomdp, state_hist, action_hist, belief_hist, safe_acts, probas, routes, mask, interp=true, obsviz=true)\n",
    "film = roll(render_hist, fps = fps, duration = duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: policy not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: policy not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[18]:1"
     ]
    }
   ],
   "source": [
    "actionvalues(policy, o0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
