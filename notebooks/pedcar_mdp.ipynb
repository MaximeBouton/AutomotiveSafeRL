{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection with a crosswalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/LocalApproximationValueIteration/Dvh7I.ji for LocalApproximationValueIteration [a40420fb-f401-52da-a663-f502e5b95060]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package LocalApproximationValueIteration does not have Random in its dependencies:\n",
      "│ - If you have LocalApproximationValueIteration checked out for development and have\n",
      "│   added Random as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with LocalApproximationValueIteration\n",
      "└ Loading Random into LocalApproximationValueIteration from project dependency, future warnings for LocalApproximationValueIteration are suppressed.\n",
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/PedCar/NmDDZ.ji for PedCar [90cf7f26-d5c7-593d-a0e1-4a8367407571]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package PedCar does not have AutomotivePOMDPs in its dependencies:\n",
      "│ - If you have PedCar checked out for development and have\n",
      "│   added AutomotivePOMDPs as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with PedCar\n",
      "└ Loading AutomotivePOMDPs into PedCar from project dependency, future warnings for PedCar are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Random\n",
    "using Printf\n",
    "using Flux\n",
    "using POMDPs\n",
    "using POMDPModelTools\n",
    "using POMDPSimulators\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using DiscreteValueIteration\n",
    "using MDPModelChecking\n",
    "using StaticArrays\n",
    "using RLInterface\n",
    "using DeepQLearning\n",
    "using AutomotiveDrivingModels\n",
    "using AutomotivePOMDPs\n",
    "using AutomotiveSensors\n",
    "using LocalApproximationValueIteration\n",
    "using Reel\n",
    "using AutoViz\n",
    "using ProgressMeter\n",
    "using JLD2\n",
    "using FileIO\n",
    "using BSON\n",
    "using PedCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "includet(\"../src/masking.jl\")\n",
    "includet(\"../src/util.jl\")\n",
    "includet(\"../src/masked_dqn.jl\")\n",
    "includet(\"../src/qmdp_approximation.jl\")\n",
    "includet(\"../src/render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1);\n",
    "cam = FitToContentCamera(0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = UrbanParams(nlanes_main=1,\n",
    "                     crosswalk_pos =[VecSE2(6, 0., pi/2), VecSE2(-6, 0., pi/2), VecSE2(0., -5., 0.)],\n",
    "                     crosswalk_length =  [14.0, 14., 14.0],\n",
    "                     crosswalk_width = [4.0, 4.0, 3.1],\n",
    "                     stop_line = 22.0)\n",
    "env = UrbanEnv(params=params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Discrete states MDP **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = PedCarMDP(env=env, pos_res=2.0, vel_res=2., ped_birth=0.7, car_birth=0.7);\n",
    "init_transition!(mdp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial resolution 2.0 m \n",
      "pedestrian velocity resolution 1.0 m/s \n",
      "car velocity resolution 2.0 m/s \n",
      "number of states 23456940 \n",
      "number of actions 4 \n"
     ]
    }
   ],
   "source": [
    "@printf(\"spatial resolution %2.1f m \\n\", mdp.pos_res)\n",
    "@printf(\"pedestrian velocity resolution %2.1f m/s \\n\", mdp.vel_ped_res)\n",
    "@printf(\"car velocity resolution %2.1f m/s \\n\", mdp.vel_res)\n",
    "@printf(\"number of states %d \\n\", n_states(mdp))\n",
    "@printf(\"number of actions %d \\n\", n_actions(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous states MDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = UrbanPOMDP(env=env,\n",
    "                   sensor = PerfectSensor(),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                   max_cars=1, \n",
    "                   max_peds=1, \n",
    "                   car_birth=0.7, \n",
    "                   ped_birth=0.7, \n",
    "                   max_obstacles=0., # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"../pc_util_processed.jld2\" qmat util pol\n",
    "safe_policy = ValueIterationPolicy(mdp, qmat, util, pol);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "mask = SafetyMask(mdp, safe_policy, threshold);\n",
    "continuous_safe_policy = SafePOMDPPolicy(mask, pomdp)\n",
    "discrete_safe_random = MaskedEpsGreedyPolicy(mdp, 1.0, mask, rng)\n",
    "continuous_safe_random = RandomMaskedPOMDPPolicy(mask, pomdp, rng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnetwork = BSON.load(\"../training_scripts/drqn-log/log10/model.bson\")[:qnetwork]\n",
    "dqn_policy = NNPolicy(pomdp, qnetwork, actions(pomdp), 1)\n",
    "masked_policy = MaskedNNPolicy(pomdp, dqn_policy, mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VI data for maksing\n",
    "# @time state_space = states(mdp);\n",
    "# vi_data = load(\"pedcar_utility.jld2\")\n",
    "# @showprogress for s in state_space\n",
    "#     if !s.crash && isterminal(mdp, s)\n",
    "#         si = stateindex(mdp, s)\n",
    "#         vi_data[\"util\"][si] = 1.0\n",
    "#         vi_data[\"qmat\"][si, :] = ones(n_actions(mdp))\n",
    "#     end\n",
    "# end\n",
    "# policy = ValueIterationPolicy(mdp, vi_data[\"qmat\"], vi_data[\"util\"], vi_data[\"pol\"]);\n",
    "# util = policy.util\n",
    "# qmat = policy.qmat\n",
    "# pol = policy.policy \n",
    "# @save \"pc_util_processed.jld2\" util qmat pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  99%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31.334661 seconds (63.57 M allocations: 11.200 GiB, 5.00% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:31\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for 10000 episodes: \n",
      "Average reward: 0.156 \n",
      "Average # of steps: 45.469 \n",
      "Average # of violations: 8.290 \n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, safe_policy, n_ep=10000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57.269925 seconds (202.65 M allocations: 24.178 GiB, 7.51% gc time)\n",
      "Summary for 10000 episodes: \n",
      "Average reward: 0.041 \n",
      "Average # of steps: 90.691 \n",
      "Average # of violations: 1.360 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:57\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, discrete_safe_random, n_ep=10000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  97%|████████████████████████████████████████ |  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.348118 seconds (49.08 M allocations: 3.586 GiB, 12.53% gc time)\n",
      "Summary for 100 episodes: \n",
      "Average reward: 0.179 \n",
      "Average # of steps: 38.400 \n",
      "Average # of violations: 3.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  99%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_policy, n_ep=100, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222.051760 seconds (1.58 G allocations: 114.417 GiB, 13.89% gc time)\n",
      "Summary for 1000 episodes: \n",
      "Average reward: 0.025 \n",
      "Average # of steps: 127.130 \n",
      "Average # of violations: 4.200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:38\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_random, n_ep=1000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Continuous Environment: Safe RL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  99%|█████████████████████████████████████████|  ETA: 0:00:01\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57.535830 seconds (307.17 M allocations: 23.332 GiB, 15.20% gc time)\n",
      "Summary for 100 episodes: \n",
      "Average reward: 0.000 \n",
      "Average # of steps: 400.000 \n",
      "Average # of violations: 0.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:58\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, masked_policy, n_ep=100, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collisions analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.445112 seconds (2.92 M allocations: 221.565 MiB, 17.06% gc time)\n"
     ]
    }
   ],
   "source": [
    "hr = HistoryRecorder(rng=rng, max_steps=400)\n",
    "s0 = initialstate(pomdp, rng)\n",
    "up = PreviousObservationUpdater()\n",
    "o0 = generate_o(pomdp, s0, UrbanAction(0.), s0, rng)\n",
    "b0 = initialize_belief(up, o0)\n",
    "@time hist2 = simulate(hr, pomdp, continuous_safe_policy, up, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:20:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:20:33\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@showprogress for ep=1:10000\n",
    "    global hist2\n",
    "    hr = HistoryRecorder(rng=rng, max_steps=100)\n",
    "    s0 = initialstate(mdp, rng)\n",
    "    hist2 = simulate(hr, mdp, rand_pol, s0)\n",
    "    if sum(hist2.reward_hist .< 0.) != 0.\n",
    "        println(\"Crash\")\n",
    "        break\n",
    "    end\n",
    "end\n",
    "h = hist2\n",
    "state_hist = h.state_hist\n",
    "action_hist = h.action_hist\n",
    "push!(action_hist, UrbanAction(NaN))\n",
    "duration, fps, render_hist = animate_states(mdp, state_hist, action_hist, mask)\n",
    "film = roll(render_hist, fps = fps, duration = duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Interact \n",
    "@manipulate for step=1:length(hist)\n",
    "    AutoViz.render(hist.state_hist[step], env, cam=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-3473895251879484063.webm?7946921848523692262\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpt6m1tI\", 0x00000000000000c5, 10.0, nothing)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = hist2\n",
    "state_hist = h.state_hist\n",
    "action_hist = h.action_hist\n",
    "belief_hist = h.belief_hist\n",
    "safe_acts = [i[1] for i in h.ainfo_hist]\n",
    "probas = [i[2] for i in h.ainfo_hist]\n",
    "routes = [i[3] for i in h.ainfo_hist]\n",
    "\n",
    "push!(safe_acts, [UrbanAction(NaN)])\n",
    "push!(probas, [NaN])\n",
    "push!(routes, PedCar.OFF_ROUTE)\n",
    "push!(action_hist, UrbanAction(NaN))\n",
    "duration, fps, render_hist = animate_states(pomdp, state_hist, action_hist, belief_hist, safe_acts, probas, routes, mask, interp=true, obsviz=true)\n",
    "film = roll(render_hist, fps = fps, duration = duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
