{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection with a crosswalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/LocalApproximationValueIteration/Dvh7I.ji for LocalApproximationValueIteration [a40420fb-f401-52da-a663-f502e5b95060]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package LocalApproximationValueIteration does not have Random in its dependencies:\n",
      "│ - If you have LocalApproximationValueIteration checked out for development and have\n",
      "│   added Random as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with LocalApproximationValueIteration\n",
      "└ Loading Random into LocalApproximationValueIteration from project dependency, future warnings for LocalApproximationValueIteration are suppressed.\n",
      "┌ Info: Recompiling stale cache file /mnt/c/Users/Maxime/wsl/.julia/compiled/v1.0/PedCar/NmDDZ.ji for PedCar [90cf7f26-d5c7-593d-a0e1-4a8367407571]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package PedCar does not have AutomotivePOMDPs in its dependencies:\n",
      "│ - If you have PedCar checked out for development and have\n",
      "│   added AutomotivePOMDPs as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with PedCar\n",
      "└ Loading AutomotivePOMDPs into PedCar from project dependency, future warnings for PedCar are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Random\n",
    "using Printf\n",
    "using Flux\n",
    "using POMDPs\n",
    "using POMDPModelTools\n",
    "using POMDPSimulators\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using DiscreteValueIteration\n",
    "using MDPModelChecking\n",
    "using StaticArrays\n",
    "using DeepRL\n",
    "using DeepQLearning\n",
    "using AutomotiveDrivingModels\n",
    "using AutomotivePOMDPs\n",
    "using AutomotiveSensors\n",
    "using LocalApproximationValueIteration\n",
    "using Reel\n",
    "using AutoViz\n",
    "using ProgressMeter\n",
    "using JLD2\n",
    "using FileIO\n",
    "using BSON\n",
    "using PedCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "includet(\"../src/masking.jl\")\n",
    "includet(\"../src/util.jl\")\n",
    "includet(\"../src/masked_dqn.jl\")\n",
    "includet(\"../src/qmdp_approximation.jl\")\n",
    "includet(\"../src/render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1);\n",
    "cam = FitToContentCamera(0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = UrbanParams(nlanes_main=1,\n",
    "                     crosswalk_pos =[VecSE2(6, 0., pi/2), VecSE2(-6, 0., pi/2), VecSE2(0., -5., 0.)],\n",
    "                     crosswalk_length =  [14.0, 14., 14.0],\n",
    "                     crosswalk_width = [4.0, 4.0, 3.1],\n",
    "                     stop_line = 22.0)\n",
    "env = UrbanEnv(params=params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Discrete states MDP **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = PedCarMDP(env=env, pos_res=2.0, vel_res=2., ped_birth=0.7, car_birth=0.7);\n",
    "init_transition!(mdp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial resolution 2.0 m \n",
      "pedestrian velocity resolution 1.0 m/s \n",
      "car velocity resolution 2.0 m/s \n",
      "number of states 23456940 \n",
      "number of actions 4 \n"
     ]
    }
   ],
   "source": [
    "@printf(\"spatial resolution %2.1f m \\n\", mdp.pos_res)\n",
    "@printf(\"pedestrian velocity resolution %2.1f m/s \\n\", mdp.vel_ped_res)\n",
    "@printf(\"car velocity resolution %2.1f m/s \\n\", mdp.vel_res)\n",
    "@printf(\"number of states %d \\n\", n_states(mdp))\n",
    "@printf(\"number of actions %d \\n\", n_actions(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous states MDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = UrbanPOMDP(env=env,\n",
    "                   sensor = PerfectSensor(),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                   max_cars=1, \n",
    "                   max_peds=1, \n",
    "                   car_birth=0.7, \n",
    "                   ped_birth=0.7, \n",
    "                   max_obstacles=0., # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"../pc_util_processed.jld2\" qmat util pol\n",
    "safe_policy = ValueIterationPolicy(mdp, qmat, util, pol);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "mask = SafetyMask(mdp, safe_policy, threshold);\n",
    "continuous_safe_policy = SafePOMDPPolicy(mask, pomdp)\n",
    "discrete_safe_random = MaskedEpsGreedyPolicy(mdp, 1.0, mask, rng)\n",
    "continuous_safe_random = RandomMaskedPOMDPPolicy(mask, pomdp, rng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnetwork = BSON.load(\"../training_scripts/drqn-log/log11/model.bson\")[:qnetwork]\n",
    "dqn_policy = NNPolicy(pomdp, qnetwork, actions(pomdp), 1)\n",
    "masked_policy = MaskedNNPolicy(pomdp, dqn_policy, mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VI data for maksing\n",
    "# @time state_space = states(mdp);\n",
    "# vi_data = load(\"pedcar_utility.jld2\")\n",
    "# @showprogress for s in state_space\n",
    "#     if !s.crash && isterminal(mdp, s)\n",
    "#         si = stateindex(mdp, s)\n",
    "#         vi_data[\"util\"][si] = 1.0\n",
    "#         vi_data[\"qmat\"][si, :] = ones(n_actions(mdp))\n",
    "#     end\n",
    "# end\n",
    "# policy = ValueIterationPolicy(mdp, vi_data[\"qmat\"], vi_data[\"util\"], vi_data[\"pol\"]);\n",
    "# util = policy.util\n",
    "# qmat = policy.qmat\n",
    "# pol = policy.policy \n",
    "# @save \"pc_util_processed.jld2\" util qmat pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33.186449 seconds (52.49 M allocations: 9.026 GiB, 5.31% gc time)\n",
      "Summary for "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:33\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 episodes: \n",
      "Average reward: 0.189 \n",
      "Average # of steps: 43.908 \n",
      "Average # of violations: 0.000 \n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, safe_policy, n_ep=10000, max_steps=100, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55.923841 seconds (173.52 M allocations: 20.131 GiB, 7.47% gc time)\n",
      "Summary for 10000 episodes: \n",
      "Average reward: 0.041 \n",
      "Average # of steps: 77.997 \n",
      "Average # of violations: 0.960 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:56\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(mdp, discrete_rand_pol, n_ep=10000, max_steps=100, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975.104676 seconds (4.19 G allocations: 310.309 GiB, 9.76% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:16:15\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for 10000 episodes: \n",
      "Average reward: 0.002 \n",
      "Average # of steps: 97.676 \n",
      "Average # of violations: 0.110 \n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_policy, n_ep=10000, max_steps=100, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072.605747 seconds (13.60 G allocations: 992.852 GiB, 15.94% gc time)\n",
      "Summary for 10000 episodes: \n",
      "Average reward: -0.000 \n",
      "Average # of steps: 99.992 \n",
      "Average # of violations: 0.030 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:34:32\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, continuous_safe_random, n_ep=10000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Environment: Safe RL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469.990081 seconds (2.56 G allocations: 186.884 GiB, 17.60% gc time)\n",
      "Summary for 1000 episodes: \n",
      "Average reward: 0.003 \n",
      "Average # of steps: 246.514 \n",
      "Average # of violations: 0.000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:07:50\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@time rewards_mask, steps_mask, violations_mask = evaluation_loop(pomdp, masked_policy, n_ep=1000, max_steps=400, rng=rng);\n",
    "print_summary(rewards_mask, steps_mask, violations_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collisions analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = HistoryRecorder(rng=rng, max_steps=100)\n",
    "s0 = initialstate(mdp, rng)\n",
    "@time hist2 = simulate(hr, mdp, safe_policy, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:20:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:   0%|                                         |  ETA: 0:20:33\u001b[39m\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@showprogress for ep=1:10000\n",
    "    global hist2\n",
    "    hr = HistoryRecorder(rng=rng, max_steps=100)\n",
    "    s0 = initialstate(mdp, rng)\n",
    "    hist2 = simulate(hr, mdp, rand_pol, s0)\n",
    "    if sum(hist2.reward_hist .< 0.) != 0.\n",
    "        println(\"Crash\")\n",
    "        break\n",
    "    end\n",
    "end\n",
    "h = hist2\n",
    "state_hist = h.state_hist\n",
    "action_hist = h.action_hist\n",
    "push!(action_hist, UrbanAction(NaN))\n",
    "duration, fps, render_hist = animate_states(mdp, state_hist, action_hist, mask)\n",
    "film = roll(render_hist, fps = fps, duration = duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hist2\n",
    "state_hist = h.state_hist\n",
    "action_hist = h.action_hist\n",
    "push!(action_hist, UrbanAction(NaN))\n",
    "duration, fps, render_hist = animate_states(mdp, state_hist, action_hist, mask)\n",
    "film = roll(render_hist, fps = fps, duration = duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
