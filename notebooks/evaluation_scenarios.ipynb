{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "using Printf\n",
    "using StaticArrays\n",
    "\n",
    "# POMDP and learning\n",
    "using POMDPs\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using POMDPSimulators\n",
    "using POMDPModelTools\n",
    "using MDPModelChecking\n",
    "using LocalApproximationValueIteration\n",
    "using RLInterface\n",
    "using DeepQLearning\n",
    "using Flux\n",
    "\n",
    "# Driving related Packages\n",
    "using AutomotiveDrivingModels\n",
    "using AutomotiveSensors\n",
    "using AutomotivePOMDPs\n",
    "using PedCar\n",
    "\n",
    "# Visualization\n",
    "using AutoViz\n",
    "using Reel\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animate_history (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/masking.jl\")\n",
    "include(\"../src/util.jl\")\n",
    "include(\"../src/masked_dqn.jl\")\n",
    "include(\"../src/qmdp_approximation.jl\")\n",
    "include(\"../src/render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1);\n",
    "cam =StaticCamera(VecE2(0., -8.), 14.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = UrbanParams(nlanes_main=1,\n",
    "                     crosswalk_pos =[VecSE2(6, 0., pi/2), VecSE2(-6, 0., pi/2), VecSE2(0., -5., 0.)],\n",
    "                     crosswalk_length =  [14.0, 14., 14.0],\n",
    "                     crosswalk_width = [4.0, 4.0, 3.1],\n",
    "                     stop_line = 22.0)\n",
    "env = UrbanEnv(params=params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = UrbanPOMDP(env=env,\n",
    "                   sensor = PerfectSensor(),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                   max_cars=4, \n",
    "                   max_peds=4, \n",
    "                   car_birth=0., \n",
    "                   ped_birth=0., \n",
    "                   max_obstacles=0, # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const TURN_RIGHT = SVector(LaneTag(3,1), LaneTag(5,1))\n",
    "const STRAIGHT_FROM_RIGHT = SVector(LaneTag(3,1), LaneTag(4,1))\n",
    "const STRAIGHT_FROM_LEFT = SVector(LaneTag(1,1), LaneTag(2,1))\n",
    "const TURN_LEFT = SVector(LaneTag(1,1), LaneTag(5,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "const RIGHT_OBSTACLE = ConvexPolygon([VecE2(8.125, -7.500), VecE2(26.875, -7.500), VecE2(26.875, -3.000), VecE2(8.125, -3.000)], 4)\n",
    "const LEFT_OBSTACLE = ConvexPolygon([VecE2(-26.875, -7.500),VecE2(-8.125, -7.500),VecE2(-8.125, -3.000),VecE2(-26.875, -3.000)], 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Policy\n",
    "\n",
    "Choose the belief updater and the policy to evaluate. \n",
    "\n",
    "Default: always choose 0. (stays still) and no belief update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionPolicy{getfield(Main, Symbol(\"##101#102\"))}(getfield(Main, Symbol(\"##101#102\"))())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set belief updater\n",
    "updater = NothingUpdater()\n",
    "\n",
    "# Set policy\n",
    "policy = FunctionPolicy(s -> UrbanAction(0.)) # constant policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 1: Perception Error\n",
    "\n",
    "It is difficult to handle perception error in rule-based policies. The POMDP framework, through the use of belief state, is well suited to address perception errors like sensor noise, false positive, false negative or sensor occlusion. \n",
    "\n",
    "### Scenario 1.1: Make some noise!\n",
    "\n",
    "Regular intersection, with cars and pedestrian, no obstacles. We are only looking at how sensor noise is taken care of.\n",
    "\n",
    "*Problem variables:*\n",
    "- car starting position and velocity\n",
    "- car route (straight, turn right, turn left)\n",
    "- car presence \n",
    "- pedestrian starting position, crosswalk, and velocity\n",
    "- pedestrian presence\n",
    "- sensor characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.083285 seconds (49.76 k allocations: 4.375 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set car parameter\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(3, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "# Set pedestrian parameter\n",
    "ped_on = false\n",
    "ped_s0 = 0.\n",
    "ped_v0 = 0.\n",
    "ped_posF = Frenet(env.ped_roadway[LaneTag(18,1)], ped_s0) # choose between 17, 18, 19\n",
    "ped = Vehicle(VehicleState(ped_posF, env.roadway, ped_v0), pomdp.ped_type, 101)\n",
    "\n",
    "# Set sensor characteristics\n",
    "pomdp.sensor = GaussianSensor(pos_noise = LinearNoise(min_noise=0.5, increase_rate=0.1),\n",
    "                              vel_noise = LinearNoise(min_noise=0.5, increase_rate=0.1),\n",
    "                              false_positive_rate = 0.1,\n",
    "                              false_negative_rate = 0.1)\n",
    "\n",
    "# Initial state\n",
    "function initialize_scenario(pomdp::UrbanPOMDP, car::Vehicle, ped::Vehicle, car_route, car_on=true, ped_on=true)\n",
    "    s0 = Scene()\n",
    "\n",
    "    if car_on\n",
    "        push!(s0, car)\n",
    "        pomdp.max_cars = 1\n",
    "        pomdp.models[2] = pomdp.car_models[car_route]\n",
    "    end\n",
    "    if ped_on\n",
    "        push!(s0, ped)\n",
    "        pomdp.max_peds = 1\n",
    "        pomdp.models[101] = IntelligentPedestrian(dt = pomdp.ΔT, crosswalk=get_lane(env.roadway, ped), conflict_lanes=get_conflict_lanes(get_lane(env.roadway, ped), env.roadway))\n",
    "    end\n",
    "\n",
    "    push!(s0, initial_ego(pomdp, rng))\n",
    "    return s0\n",
    "end\n",
    "s0 = initialize_scenario(pomdp, car, ped, STRAIGHT_FROM_RIGHT, car_on, ped_on)\n",
    "\n",
    "# Static scenario specs\n",
    "empty_obstacles!(env)\n",
    "pomdp.ped_birth = 0.\n",
    "pomdp.car_birth = 0.\n",
    "\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "hr = HistoryRecorder(max_steps=100, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-1273849684007332129.webm?18025518308785908272\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpJLgiDU\", 0x0000000000000064, 20.0, nothing)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                obs_overlays = o -> [GaussianSensorOverlay(sensor=pomdp.sensor, o=[veh for veh in obs_to_scene(pomdp, o) if veh.id != EGO_ID], color=MONOKAI[\"color2\"])],\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1.2: Blind Corners\n",
    "\n",
    "A similar scenario than above, with sensor occlusions. \n",
    "\n",
    "*Problem variables:*\n",
    "- car starting position\n",
    "- car route (straight, turn right, turn left)\n",
    "- car presence \n",
    "- pedestrian starting position and crosswalk \n",
    "- pedestrian presence\n",
    "- sensor characteristics\n",
    "- obstacle location: right or left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.070644 seconds (50.76 k allocations: 4.559 MiB)\n"
     ]
    }
   ],
   "source": [
    "# set obstacles\n",
    "pomdp.max_obstacles = 1\n",
    "env.obstacles = [RIGHT_OBSTACLE]\n",
    "\n",
    "# set car position\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(1, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "s0 = initialize_scenario(pomdp, car, ped, TURN_LEFT, ped_on=false)\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=100, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-14320509571463263514.webm?2008355610765980071\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmppEl6Db\", 0x0000000000000064, 20.0, nothing)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                state_overlays = s -> [BlinkerOverlay(right=false, on=true, veh=v) for v in s if v.id==2],\n",
    "                obs_overlays = o -> [GaussianSensorOverlay(sensor=GaussianSensor(), o=[veh for veh in obs_to_scene(pomdp, o) if veh.id != EGO_ID], color=MONOKAI[\"color2\"])],\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 2: Interactions\n",
    "\n",
    "The POMDP approach can capture interaction between other traffic participants such as a vehicle yielding for a pedestrian or letting the right of way to our vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2.1: Vehicle - Pedestrian interaction\n",
    "\n",
    "*Problem variables:*\n",
    "- car starting position\n",
    "- car route (straight, turn right, turn left)\n",
    "- car presence \n",
    "- pedestrian starting position and crosswalk \n",
    "- pedestrian presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.060838 seconds (48.60 k allocations: 4.245 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set car parameters\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(1, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "# Set pedestrian parameters\n",
    "ped_on = true\n",
    "ped_s0 = 2.\n",
    "ped_v0 = 0.\n",
    "ped_posF = Frenet(env.ped_roadway[LaneTag(17,1)], ped_s0) # choose between 17, 18, 19\n",
    "ped = Vehicle(VehicleState(ped_posF, env.roadway, ped_v0), pomdp.ped_type, 101)\n",
    "\n",
    "# Sensor \n",
    "pomdp.sensor = PerfectSensor()\n",
    "empty_obstacles!(pomdp.env)\n",
    "\n",
    "s0 = initialize_scenario(pomdp, car, ped, STRAIGHT_FROM_RIGHT)\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=100, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-1018704810602977942.webm?12069612459311734450\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpha5Crx\", 0x0000000000000064, 20.0, nothing)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2.2: Vehicle - Vehicle interactions\n",
    "\n",
    "I am currently unsure if it is relevant. \n",
    "\n",
    "A possible situation is one where the ego vehicle is starting the turn while a car on the right arrives, intending to make a left turn and is then going to let the priority to the ego vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.153413 seconds (99.62 k allocations: 6.061 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set car parameter\n",
    "car_s0 = 10.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(1, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "# Sensor \n",
    "pomdp.sensor = PerfectSensor()\n",
    "\n",
    "s0 = initialize_scenario(pomdp, car, ped, TURN_LEFT, ped_on=false)\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "# Change the policy\n",
    "slow_policy = FunctionPolicy(x->UrbanAction(0.5))\n",
    "\n",
    "hr = HistoryRecorder(max_steps=50, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, slow_policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-1415220889096329073.webm?13038639471322305399\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmp7uiFxv\", 0x0000000000000032, 20.0, nothing)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                state_overlays = s -> [BlinkerOverlay(right=false, on=true, veh=v) for v in s if v.id==2],\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 3: Scalability\n",
    "\n",
    "Our approach scales to multiple cars, pedestrians and obstacles. Conventional rule-based approach are very difficult to design in such scenarios since there are a lot of cases to take into account.\n",
    "\n",
    "*Problem variables:*\n",
    "- Maximum number of cars \n",
    "- Maximum number of pedestrian \n",
    "- Probability of appearance of cars \n",
    "- Probability of appearance of pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.171657 seconds (217.66 k allocations: 13.926 MiB)\n"
     ]
    }
   ],
   "source": [
    "pomdp.max_cars = 3.\n",
    "pomdp.max_peds = 3.\n",
    "pomdp.car_birth = 0.3\n",
    "pomdp.ped_birth = 0.3\n",
    "pomdp.max_obstacles = 0.\n",
    "\n",
    "s0 = initialstate(pomdp, rng)\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=200, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-3852922535116155368.webm?1800864598543011673\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpxsS1MH\", 0x00000000000000c8, 20.0, nothing)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "5390a2797ba5432f87e3280503b7f2dc",
   "lastKernelId": "d86a20d1-0745-42e2-bcf1-cd6593c78b59"
  },
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
