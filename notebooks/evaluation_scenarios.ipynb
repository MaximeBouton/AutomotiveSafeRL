{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Flux.params in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Random\n",
    "using Printf\n",
    "using StaticArrays\n",
    "\n",
    "# POMDP and learning\n",
    "using POMDPs\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using POMDPSimulators\n",
    "using POMDPModelTools\n",
    "using MDPModelChecking\n",
    "using LocalApproximationValueIteration\n",
    "using DeepRL\n",
    "using DeepQLearning\n",
    "using Flux\n",
    "\n",
    "# Driving related Packages\n",
    "using AutomotiveDrivingModels\n",
    "using AutomotiveSensors\n",
    "using AutomotivePOMDPs\n",
    "using PedCar\n",
    "\n",
    "# Visualization\n",
    "using AutoViz\n",
    "using Reel\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animate_history (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/masking.jl\")\n",
    "include(\"../src/util.jl\")\n",
    "include(\"../src/masked_dqn.jl\")\n",
    "include(\"../src/qmdp_approximation.jl\")\n",
    "include(\"../src/render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environment parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1);\n",
    "cam =StaticCamera(VecE2(0., -8.), 14.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = UrbanParams(nlanes_main=1,\n",
    "                     crosswalk_pos =[VecSE2(6, 0., pi/2), VecSE2(-6, 0., pi/2), VecSE2(0., -5., 0.)],\n",
    "                     crosswalk_length =  [14.0, 14., 14.0],\n",
    "                     crosswalk_width = [4.0, 4.0, 3.1],\n",
    "                     stop_line = 22.0)\n",
    "env = UrbanEnv(params=params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp = UrbanPOMDP(env=env,\n",
    "                   sensor = PerfectSensor(),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                   max_cars=0, \n",
    "                   max_peds=0, \n",
    "                   car_birth=0., \n",
    "                   ped_birth=0., \n",
    "                   max_obstacles=0, # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "const TURN_RIGHT = SVector(LaneTag(3,1), LaneTag(5,1))\n",
    "const STRAIGHT_FROM_RIGHT = SVector(LaneTag(3,1), LaneTag(4,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant RIGHT_OBSTACLE\n",
      "WARNING: redefining constant LEFT_OBSTACLE\n"
     ]
    }
   ],
   "source": [
    "const RIGHT_OBSTACLE = ConvexPolygon([VecE2(8.125, -7.500), VecE2(26.875, -7.500), VecE2(26.875, -3.000), VecE2(8.125, -3.000)], 4)\n",
    "const LEFT_OBSTACLE = ConvexPolygon([VecE2(-26.875, -7.500),VecE2(-8.125, -7.500),VecE2(-8.125, -3.000),VecE2(-26.875, -3.000)], 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set belief updater\n",
    "updater = NothingUpdater()\n",
    "\n",
    "# Set policy\n",
    "policy = FunctionPolicy(s -> UrbanAction(0.)) # constant policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 1: Perception Error\n",
    "\n",
    "It is difficult to handle perception error in rule-based policies. The POMDP framework, through the use of belief state, is well suited to address perception errors like sensor noise, false positive, false negative or sensor occlusion. \n",
    "\n",
    "**Scenario 1: Make some noise!**\n",
    "Regular intersection, with cars and pedestrian, no obstacles. We are only looking at how sensor noise is taken care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.189078 seconds (203.00 k allocations: 14.045 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set car parameter\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(3, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "# Set pedestrian parameter\n",
    "ped_on = true\n",
    "ped_s0 = 0.\n",
    "ped_v0 = 0.\n",
    "ped_posF = Frenet(env.ped_roadway[LaneTag(18,1)], ped_s0) # choose between 17, 18, 19\n",
    "ped = Vehicle(VehicleState(ped_posF, env.roadway, ped_v0), pomdp.ped_type, 101)\n",
    "\n",
    "# Set sensor characteristics\n",
    "pomdp.sensor = GaussianSensor(pos_noise = LinearNoise(min_noise=0.5, increase_rate=0.1),\n",
    "                              vel_noise = LinearNoise(min_noise=0.5, increase_rate=0.1),\n",
    "                              false_positive_rate = 0.1,\n",
    "                              false_negative_rate = 0.1)\n",
    "\n",
    "# Initial state\n",
    "function initialize_scenario(pomdp::UrbanPOMDP, car::Vehicle, ped::Vehicle)\n",
    "    s0 = Scene()\n",
    "\n",
    "    if car_on\n",
    "        push!(s0, car)\n",
    "        pomdp.max_cars = 1\n",
    "        pomdp.models[2] = pomdp.car_models[TURN_RIGHT]\n",
    "    end\n",
    "    if ped_on\n",
    "        push!(s0, ped)\n",
    "        pomdp.max_peds = 1\n",
    "        pomdp.models[101] = IntelligentPedestrian(dt = pomdp.ΔT, crosswalk=get_lane(env.roadway, ped), conflict_lanes=get_conflict_lanes(get_lane(env.roadway, ped), env.roadway))\n",
    "    end\n",
    "\n",
    "    push!(s0, initial_ego(pomdp, rng))\n",
    "    return s0\n",
    "end\n",
    "s0 = initialize_scenario(pomdp, car, ped)\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=200, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-17932019211769908887.webm?17685512286142309668\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpPrBHJq\", 0x00000000000000c8, 20.0, nothing)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: /mnt/c/Users/Maxime/wsl/.julia/packages/DeepQLearning/EeLUa/src is not an existing directory, Revise is not watching\n",
      "└ @ Revise /mnt/c/Users/Maxime/wsl/.julia/packages/Revise/TmjcT/src/Revise.jl:361\n",
      "┌ Warning: /mnt/c/Users/Maxime/wsl/.julia/packages/DeepRL/ynDbA/src is not an existing directory, Revise is not watching\n",
      "└ @ Revise /mnt/c/Users/Maxime/wsl/.julia/packages/Revise/TmjcT/src/Revise.jl:361\n"
     ]
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                obs_overlays = o -> [GaussianSensorOverlay(sensor=pomdp.sensor, o=[veh for veh in obs_to_scene(pomdp, o) if veh.id != EGO_ID], color=MONOKAI[\"color2\"])],\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 2: Blind Corners**\n",
    "A similar scenario than above, with sensor occlusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.087423 seconds (125.13 k allocations: 10.076 MiB)\n"
     ]
    }
   ],
   "source": [
    "pomdp.max_obstacles = 1\n",
    "env.obstacles = [LEFT_OBSTACLE]\n",
    "\n",
    "s0 = initialize_scenario(pomdp, car, ped)\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=200, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-6475540927874529440.webm?195153532644085012\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpHafC9Q\", 0x00000000000000c8, 20.0, nothing)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                obs_overlays = o -> [GaussianSensorOverlay(sensor=pomdp.sensor, o=[veh for veh in obs_to_scene(pomdp, o) if veh.id != EGO_ID], color=MONOKAI[\"color2\"])],\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 2: Interactions\n",
    "\n",
    "The POMDP approach can capture interaction between other traffic participants such as a vehicle yielding for a pedestrian or letting the right of way to our vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 1: Vehicle - Pedestrian interaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.091084 seconds (59.66 k allocations: 6.383 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set car parameter\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(1, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)\n",
    "\n",
    "# Set pedestrian parameter\n",
    "ped_on = true\n",
    "ped_s0 = 2.\n",
    "ped_v0 = 0.\n",
    "ped_posF = Frenet(env.ped_roadway[LaneTag(17,1)], ped_s0) # choose between 17, 18, 19\n",
    "ped = Vehicle(VehicleState(ped_posF, env.roadway, ped_v0), pomdp.ped_type, 101)\n",
    "\n",
    "# Sensor \n",
    "pomdp.sensor = PerfectSensor()\n",
    "\n",
    "s0 = initialize_scenario(pomdp, car, ped)\n",
    "\n",
    "# Initial belief \n",
    "b0 = nothing\n",
    "\n",
    "hr = HistoryRecorder(max_steps=200, rng=rng)\n",
    "@time hist = POMDPSimulators.simulate(hr, pomdp, policy, updater, b0, s0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"files/reel-14003076230573301246.webm?648011025927107625\" type=\"video/webm\"></video>"
      ],
      "text/plain": [
       "Frames{MIME{Symbol(\"image/png\")}}(\"/tmp/tmpOfQwmR\", 0x00000000000000c8, 20.0, nothing)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_history(hist, pomdp,\n",
    "                step_overlays = s -> [TextOverlay(text = [\"step: $s\"], font_size=20, pos=VecE2(pomdp.env.params.x_min + 3.,4.), incameraframe=true)],\n",
    "                extra_overlays = [IDOverlay()],\n",
    "                speed_factor = 2,\n",
    "                cam =  cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 2: Vehicle - Vehicle interactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set car parameter\n",
    "car_on = true\n",
    "car_s0 = 0.\n",
    "car_v0 = 0.\n",
    "car_posF = Frenet(env.roadway[LaneTag(1, 1)], car_s0)\n",
    "car = Vehicle(VehicleState(car_posF, env.roadway, car_v0), pomdp.car_type, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 3: Scalability\n",
    "\n",
    "Our approach scales to multiple cars, pedestrians and obstacles. Conventional rule-based approach are very difficult to design in such scenarios since there are a lot of cases to take into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
