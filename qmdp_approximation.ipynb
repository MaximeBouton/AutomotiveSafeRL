{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belief State Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "using Printf\n",
    "using StaticArrays\n",
    "using Flux\n",
    "using FileIO\n",
    "using BSON: @load\n",
    "using JLD2\n",
    "using ProgressMeter\n",
    "using POMDPs\n",
    "using POMDPModelTools\n",
    "using DeepRL\n",
    "using DeepQLearning\n",
    "using LocalApproximationValueIteration\n",
    "using DiscreteValueIteration\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using AutomotivePOMDPs\n",
    "using MDPModelChecking\n",
    "using PedCar\n",
    "using AutomotiveSensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"masking.jl\")\n",
    "include(\"util.jl\")\n",
    "include(\"masked_dqn.jl\")\n",
    "include(\"render_helpers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module RNNFiltering.\n"
     ]
    }
   ],
   "source": [
    "include(\"training_scripts/RNNFiltering/RNNFiltering.jl\")\n",
    "using Main.RNNFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MersenneTwister(1)\n",
    "cam = FitToContentCamera(0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = PedCarMDP(pos_res=2.0, vel_res=2., ped_birth=0.7, car_birth=0.7)\n",
    "pomdp = UrbanPOMDP(env=mdp.env,\n",
    "                    sensor = GaussianSensor(false_positive_rate=0.0, \n",
    "                                            pos_noise = LinearNoise(min_noise=0.5, increase_rate=0.05), \n",
    "                                            vel_noise = LinearNoise(min_noise=0.5, increase_rate=0.05)),\n",
    "                   ego_goal = LaneTag(2, 1),\n",
    "                     obs_dist = ObstacleDistribution(mdp.env, upper_obs_pres_prob=0., left_obs_pres_prob=1.0, right_obs_pres_prob=1.0),\n",
    "                   max_cars=1, \n",
    "                   max_peds=1, \n",
    "                   car_birth=0.05, \n",
    "                   ped_birth=0.05, \n",
    "                   max_obstacles=1, # no fixed obstacles\n",
    "                   lidar=false,\n",
    "                   ego_start=20,\n",
    "                   ΔT=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DRQN Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SafetyMask{PedCarMDP,ValueIterationPolicy}(PedCarMDP\n",
       "  env: UrbanEnv\n",
       "  ΔT: Float64 0.5\n",
       "  pos_res: Float64 2.0\n",
       "  vel_res: Float64 2.0\n",
       "  vel_ped_res: Float64 1.0\n",
       "  car_action_space: Array{Float64}((14,)) [-9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
       "  ped_action_space: Array{Float64}((3,)) [0.0, 1.0, 2.0]\n",
       "  car_models: Dict{SArray{Tuple{2},LaneTag,1,2},DriverModel}\n",
       "  car_type: VehicleDef\n",
       "  ego_type: VehicleDef\n",
       "  ped_type: VehicleDef\n",
       "  a_noise: Float64 1.0\n",
       "  v_noise: Float64 1.0\n",
       "  ped_birth: Float64 0.7\n",
       "  car_birth: Float64 0.7\n",
       "  ego_start: Float64 20.0\n",
       "  ego_goal: LaneTag\n",
       "  off_grid: VehicleState\n",
       "  collision_cost: Float64 -1.0\n",
       "  action_cost: Float64 0.0\n",
       "  goal_reward: Float64 1.0\n",
       "  γ: Float64 0.95\n",
       "  _ped_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{3}}\n",
       "  _car_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{2}}\n",
       "  _l_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{1}}\n",
       "  _v_grid: GridInterpolations.RectangleGrid{1}\n",
       "  _car_transition_dict: Dict{Tuple{VehicleState,SArray{Tuple{2},LaneTag,1,2},LonAccelDirection},SparseCat{Array{Tuple{VehicleState,SArray{Tuple{2},LaneTag,1,2}},1},Array{Float64,1}}}\n",
       "  _ped_transition_dict: Dict{Tuple{VehicleState,ConstantSpeedDawdling},SparseCat{Array{VehicleState,1},Array{Float64,1}}}\n",
       "  _ego_transition_dict: Dict{Tuple{VehicleState,LonAccelDirection},SparseCat{Array{VehicleState,1},Array{Float64,1}}}\n",
       "  _collision_checker: Dict{Tuple{VehicleState,VehicleState,VehicleState},Bool}\n",
       ", ValueIterationPolicy([1.0 1.0 1.0 1.0; 1.0 1.0 1.0 1.0; … ; 1.0 1.0 1.0 1.0; 1.0 1.0 1.0 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], UrbanAction[UrbanAction(-4.0), UrbanAction(-2.0), UrbanAction(0.0), UrbanAction(2.0)], true, PedCarMDP\n",
       "  env: UrbanEnv\n",
       "  ΔT: Float64 0.5\n",
       "  pos_res: Float64 2.0\n",
       "  vel_res: Float64 2.0\n",
       "  vel_ped_res: Float64 1.0\n",
       "  car_action_space: Array{Float64}((14,)) [-9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
       "  ped_action_space: Array{Float64}((3,)) [0.0, 1.0, 2.0]\n",
       "  car_models: Dict{SArray{Tuple{2},LaneTag,1,2},DriverModel}\n",
       "  car_type: VehicleDef\n",
       "  ego_type: VehicleDef\n",
       "  ped_type: VehicleDef\n",
       "  a_noise: Float64 1.0\n",
       "  v_noise: Float64 1.0\n",
       "  ped_birth: Float64 0.7\n",
       "  car_birth: Float64 0.7\n",
       "  ego_start: Float64 20.0\n",
       "  ego_goal: LaneTag\n",
       "  off_grid: VehicleState\n",
       "  collision_cost: Float64 -1.0\n",
       "  action_cost: Float64 0.0\n",
       "  goal_reward: Float64 1.0\n",
       "  γ: Float64 0.95\n",
       "  _ped_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{3}}\n",
       "  _car_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{2}}\n",
       "  _l_grid: Dict{LaneTag,GridInterpolations.RectangleGrid{1}}\n",
       "  _v_grid: GridInterpolations.RectangleGrid{1}\n",
       "  _car_transition_dict: Dict{Tuple{VehicleState,SArray{Tuple{2},LaneTag,1,2},LonAccelDirection},SparseCat{Array{Tuple{VehicleState,SArray{Tuple{2},LaneTag,1,2}},1},Array{Float64,1}}}\n",
       "  _ped_transition_dict: Dict{Tuple{VehicleState,ConstantSpeedDawdling},SparseCat{Array{VehicleState,1},Array{Float64,1}}}\n",
       "  _ego_transition_dict: Dict{Tuple{VehicleState,LonAccelDirection},SparseCat{Array{VehicleState,1},Array{Float64,1}}}\n",
       "  _collision_checker: Dict{Tuple{VehicleState,VehicleState,VehicleState},Bool}\n",
       "), 0.999)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.999\n",
    "problem_file=\"training-script/drqn/log7/problem.jld\"\n",
    "weights_file=\"training-script/drqn/log7/weights.jld\"\n",
    "@load \"pc_processed.bson\" qmat util pol\n",
    "safe_policy = ValueIterationPolicy(mdp, qmat, util, pol)\n",
    "mask = SafetyMask(mdp, safe_policy, threshold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error encountered while loading \"training-script/drqn/log7/problem.jld\".\n",
      "Fatal error:\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package JLD not found in current path:\n- Run `Pkg.add(\"JLD\")` to install the JLD package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package JLD not found in current path:\n- Run `Pkg.add(\"JLD\")` to install the JLD package.\n",
      ""
     ]
    }
   ],
   "source": [
    "solver = load(problem_file)[\"solver\"]\n",
    "env_ = POMDPEnvironment(pomdp)\n",
    "graph = TensorFlow.Graph()\n",
    "train_graph = DeepQLearning.build_graph(solver, env_, graph)\n",
    "policy = DeepQLearning.restore_policy(env_, solver, train_graph, weights_file)\n",
    "masked_policy = MaskedDQNPolicy(pomdp, policy, mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RNN Belief Updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 2\n",
    "models = Vector{Chain}(undef, n_models)\n",
    "for i=1:n_models\n",
    "    models[i] = BSON.load(\"training_scripts/RNNFiltering/model_$i.bson\")[:model] \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beliefs = Vector{Vector{Float64}}(n_models)\n",
    "for i=1:n_models       \n",
    "    pred = models[i](o).tracker.data\n",
    "    b_ = process_prediction(pomdp, pred, o)\n",
    "    beliefs[i] = b_\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Chain not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Chain not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at none:0"
     ]
    }
   ],
   "source": [
    "struct PedCarRNNUpdater <: Updater \n",
    "    models::Vector{Chain}\n",
    "    beliefs::Vector{Vector{Float64}}\n",
    "    mdp::PedCarMDP\n",
    "    pomdp::UrbanPOMDP\n",
    "end\n",
    "\n",
    "function POMDPs.update(up::PedCarRNNUpdater, bold, a, o::Vector{Float64})\n",
    "    n_models = length(up.models)\n",
    "    for i=1:n_models       \n",
    "        pred = models[i](o).tracker.data\n",
    "        up.beliefs[i] = pred\n",
    "    end\n",
    "    return up.beliefs\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function action(policy::MaskedDQNPolicy, b::Vector{Vector{Float64}})\n",
    "    safe_acts = safe_actions(policy.problem, policy.mask, b)\n",
    "    val = value(policy.q, b)\n",
    "    act = best_action(acts, val, policy.problem)\n",
    "    return act\n",
    "end\n",
    "\n",
    "function value(policy::DQNPolicy, b::Vector{UrbanState})\n",
    "    n_features = 4\n",
    "    pomdp = policy.env.problem\n",
    "    vals = zeros(n_actions(pomdp))\n",
    "    for i=1:length(b)\n",
    "        bb = process_prediction(pomdp, pred, b[i])\n",
    "        vals += value(policy, bb)\n",
    "    end\n",
    "    return vals./length(b)\n",
    "end\n",
    "\n",
    "function POMDPs.safe_actions(pomdp::UrbanPOMDP, mask::SafetyMask{PedCar, P}, b::Vector{Vector{Float64}}) where P <: Policy\n",
    "    vals = zeros(n_actions(pomdp))\n",
    "    for i=1:length(b)\n",
    "        bb = process_prediction(pomdp, pred, b[i])\n",
    "        s = obs_to_scene(pomdp, o)\n",
    "        vals += compute_probas(pomdp, mask, s, PED_ID, CAR_ID)# need to change b\n",
    "    end\n",
    "    vals ./= length(b)\n",
    "    \n",
    "    safe_acts = UrbanAction[]\n",
    "    sizehint!(safe_acts, n_actions(mask.mdp))\n",
    "    action_space = actions(mask.mdp)\n",
    "    if maximum(p_sa) <= mask.threshold\n",
    "        push!(safe_acts, action_space[indmax(vals)])\n",
    "    else\n",
    "        for (j, a) in enumerate(action_space)\n",
    "            if vals[j] > mask.threshold\n",
    "                push!(safe_acts, a)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return safe_acts\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
